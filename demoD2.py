# Sara Helena RÃ©gis Theiss

from numpy.lib.nanfunctions import nanargmin
import scipy.io as scipy
from math import sqrt
from collections import Counter as ct
from statistics import mode
import matplotlib.pyplot as plt
import numpy as np

# busca valor da caracterÃ­stica 'indice' de dados que correspondem ao rotulo passado 
def get_dados_rotulo(dados, rotulos, rotulo, indice):
    ret = []
    for idx in range(0, len(dados)):
        if(rotulos[idx] == rotulo):
            ret.append(dados[idx][indice])
    return ret

# cria grÃ¡fico onde cada elemento de dados Ã© representado de acordo com seu rÃ³tulo nas coordenadas das duas dimensÃµes escolhidas
def visualiza_pontos(dados, rotulos, d1, d2):
    fig, ax = plt.subplots()
    ax.scatter(get_dados_rotulo(dados, rotulos, 1, d1), get_dados_rotulo(dados, rotulos, 1, d2), c='red' , marker='^')
    ax.scatter(get_dados_rotulo(dados, rotulos, 2, d1), get_dados_rotulo(dados, rotulos, 2, d2), c='blue' , marker='+')
    ax.scatter(get_dados_rotulo(dados, rotulos, 3, d1), get_dados_rotulo(dados, rotulos, 3, d2), c='green', marker='.')
    plt.show()

# calcula a acurÃ¡cia entre os rÃ³tulos previstos e os rÃ³tulos de teste
def acuracia(previstos, teste):
    # calcula o nÃºmero de rÃ³tulos previstos corretamente
    num_corretos = 0
    for i in range(len(previstos)):
        num_corretos += 1 if previstos[i] == teste[i,0] else 0

    total_num = len(teste)
    acuracia = num_corretos / total_num * 100
    return acuracia

# calcula a distÃ¢ncia entre os elementos a e b, sendo n a dimensÃ£o deles
def dist(a, b, n):
    soma_dimensoes = 0

    try:
        for i in range(n):
            soma_dimensoes += (b[i] - a[i]) ** 2
        return sqrt(soma_dimensoes)
    except IndexError:
        print('DimensÃ£o invÃ¡lida para os elementos!')

# faz a normalizaÃ§Ã£o dos dados passados
def normalizacao(dados):
    n = len(dados[0]) # nÃºmero de colunas/caracterÃ­sticas
    valores_fixos = []

    # salva os valores que serÃ£o fixos para cada coluna, como o valor mÃ­nimo encontrado
    # e o cÃ¡lculo do valor mÃ­nimo subtraÃ­do do valor mÃ¡ximo 
    for i in range(n):
        x = [row[i] for row in dados]
        valores = []
        valores.append(min(x)) # ğ‘€ğ‘–ğ‘›(ğ‘‹)
        valores.append(max(x) - valores[0]) # ğ‘€ğ‘ğ‘¥ ğ‘‹ âˆ’ğ‘€ğ‘–ğ‘›(ğ‘‹)
        valores_fixos.append(valores) # valores fixos da coluna i de dados
    
    novos_dados = [] # cria nova matriz de dados para nÃ£o modificar a matriz original
    for i in range(len(dados)):
        elemento = []
        for j in range(n):
            # ğ‘(ğ‘‹) = [ğ‘‹âˆ’ğ‘€ğ‘–ğ‘›(ğ‘‹)] / ğ‘€ğ‘ğ‘¥ ğ‘‹ âˆ’ğ‘€ğ‘–ğ‘›(ğ‘‹)
            elemento.append((dados[i][j] - valores_fixos[j][0]) / valores_fixos[j][1])
        novos_dados.append(elemento)
    
    return np.array(novos_dados)


# classifica cada valor de teste de acordo com os exemplos de treinamento mais prÃ³ximos a eles
# adicionado parÃ¢metro normalizar, que quando True habilita a normalizaÃ§Ã£o dos dados 
def meu_knn(dados_train, rotulo_train, dados_teste, k, normalizar):
    rotulos = []

    if normalizar:
        # aplica normalizaÃ§Ã£o aos dados
        dados_teste = normalizacao(dados_teste)
        dados_train = normalizacao(dados_train)

    for i in range(len(dados_teste)):
        distancia_teste_train = []
        for j in range(len(dados_train)):
            # calcula a distÃ¢ncia entre o elemento i de teste e o elemento j de treinamento
            distancia_teste_train.append(dist(dados_teste[i], dados_train[j], len(dados_teste[i])))

        # ordena a lista de distÃ¢ncia e rÃ³tulos juntos para que fiquem com os mesmos Ã­ndices nos 
        # elementos correspondentes; entÃ£o, seleciona a lista com os rÃ³tulos jÃ¡ ordenados
        rotulos_ordenados = [y for x, y in sorted(zip(distancia_teste_train, rotulo_train))]

        # salva somente a coluna com os rÃ³tulos, que Ã© o valor interessante para o problema
        rotulos_ordenados = [row[0] for row in rotulos_ordenados]

        # seleciona os k primeiros elementos dos rÃ³tulos, calcula a quantidade de ocorrÃªncias 
        # para cada valor e pega o valor mais comum encontrado
        rotulos.append(ct(rotulos_ordenados[:k]).most_common(1)[0][0])
    
    return rotulos

# carrega grupo de dados
mat = scipy.loadmat('grupoDados2.mat')
grupo_test = mat['grupoTest']
grupo_train = mat['grupoTrain']
test_rots = mat['testRots']
train_rots = mat['trainRots']

# Q2.1: Aplique seu kNN a este problema. Qual Ã© a sua acurÃ¡cia de classificaÃ§Ã£o?
# Aplicando o kNN com k igual a 1, obteve-se uma acurÃ¡cia de aproximadamente 68,33%
rotulo_previsto_1 = meu_knn(grupo_train, train_rots, grupo_test, 1, False)
valor_acuracia_1 = acuracia(rotulo_previsto_1, test_rots)
print('Q2.1 - AcurÃ¡cia obtida: ', valor_acuracia_1, end='%\n\n')
visualiza_pontos(grupo_test, rotulo_previsto_1, 8, 9)


# Q2.2: A acurÃ¡cia pode ser igual a 98% com o kNN. Descubra por que o resultado atual Ã© muito menor.
#       Ajuste o conjunto de dados ou k de tal forma que a acurÃ¡cia se torne 98% e explique o que vocÃª fez e
#       por quÃª.

# O valor Ã© muito menor, o intervalo de valor de cada caracterÃ­stica varia muito de uma para outra.
# Com isso, uma Ãºnica caracterÃ­stica pode estar dominando as medidas de distÃ¢ncia calculadas.
# Para obter uma acurÃ¡cia de 98%, foi aplicada a normalizaÃ§Ã£o dos dados no grupo de teste e grupo de treinamento, com k igual a 1.
# No cÃ³digo abaixo, Ã© representado ao passar True no Ãºltimo parÃ¢metro do mÃ©todo meu_knn (parÃ¢metro 'normalizar'):

rotulo_previsto_2 = meu_knn(grupo_train, train_rots, grupo_test, 1, True)
valor_acuracia_2 = acuracia(rotulo_previsto_2, test_rots)
print('Q2.2 - AcurÃ¡cia obtida: ', valor_acuracia_2, end='%\n\n')
visualiza_pontos(grupo_test, rotulo_previsto_2, 8, 9)
visualiza_pontos(grupo_test, test_rots, 8, 9)