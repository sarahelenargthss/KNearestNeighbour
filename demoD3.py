# Sara Helena R√©gis Theiss

from numpy.lib.nanfunctions import nanargmin
import scipy.io as scipy
from math import sqrt
from collections import Counter as ct
from statistics import mode
import matplotlib.pyplot as plt
import numpy as np

# busca valor da caracter√≠stica 'indice' de dados que correspondem ao rotulo passado 
def get_dados_rotulo(dados, rotulos, rotulo, indice):
    ret = []
    for idx in range(0, len(dados)):
        if(rotulos[idx] == rotulo):
            ret.append(dados[idx][indice])
    return ret

# cria gr√°fico onde cada elemento de dados √© representado de acordo com seu r√≥tulo nas coordenadas das duas dimens√µes escolhidas
def visualiza_pontos(dados, rotulos, d1, d2):
    fig, ax = plt.subplots()
    ax.scatter(get_dados_rotulo(dados, rotulos, 1, d1), get_dados_rotulo(dados, rotulos, 1, d2), c='red' , marker='^')
    ax.scatter(get_dados_rotulo(dados, rotulos, 2, d1), get_dados_rotulo(dados, rotulos, 2, d2), c='blue' , marker='+')
    ax.scatter(get_dados_rotulo(dados, rotulos, 3, d1), get_dados_rotulo(dados, rotulos, 3, d2), c='green', marker='.')
    plt.show()

# calcula a acur√°cia entre os r√≥tulos previstos e os r√≥tulos de teste
def acuracia(previstos, teste):
    # calcula o n√∫mero de r√≥tulos previstos corretamente
    num_corretos = 0
    for i in range(len(previstos)):
        num_corretos += 1 if previstos[i] == teste[i,0] else 0

    total_num = len(teste)
    acuracia = num_corretos / total_num * 100
    return acuracia

# calcula a dist√¢ncia entre os elementos a e b, sendo n a dimens√£o deles
def dist(a, b, n):
    soma_dimensoes = 0

    try:
        for i in range(n):
            soma_dimensoes += (b[i] - a[i]) ** 2
        return sqrt(soma_dimensoes)
    except IndexError:
        print('Dimens√£o inv√°lida para os elementos!')

# faz a normaliza√ß√£o dos dados passados
def normalizacao(dados):
    n = len(dados[0]) # n√∫mero de colunas/caracter√≠sticas
    valores_fixos = []

    # salva os valores que ser√£o fixos para cada coluna, como o valor m√≠nimo encontrado
    # e o c√°lculo do valor m√≠nimo subtra√≠do do valor m√°ximo 
    for i in range(n):
        x = [row[i] for row in dados]
        valores = []
        valores.append(min(x)) # ùëÄùëñùëõ(ùëã)
        valores.append(max(x) - valores[0]) # ùëÄùëéùë• ùëã ‚àíùëÄùëñùëõ(ùëã)
        valores_fixos.append(valores) # valores fixos da coluna i de dados
    
    novos_dados = [] # cria nova matriz de dados para n√£o modificar a matriz original
    for i in range(len(dados)):
        elemento = []
        for j in range(n):
            # ùëÅ(ùëã) = [ùëã‚àíùëÄùëñùëõ(ùëã)] / ùëÄùëéùë• ùëã ‚àíùëÄùëñùëõ(ùëã)
            elemento.append((dados[i][j] - valores_fixos[j][0]) / valores_fixos[j][1])
        novos_dados.append(elemento)
    
    return np.array(novos_dados)


# classifica cada valor de teste de acordo com os exemplos de treinamento mais pr√≥ximos a eles
# adicionado par√¢metro normalizar, que quando True habilita a normaliza√ß√£o dos dados 
def meu_knn(dados_train, rotulo_train, dados_teste, k, normalizar):
    rotulos = []

    if normalizar:
        # aplica normaliza√ß√£o aos dados
        dados_teste = normalizacao(dados_teste)
        dados_train = normalizacao(dados_train)

    for i in range(len(dados_teste)):
        distancia_teste_train = []
        for j in range(len(dados_train)):
            # calcula a dist√¢ncia entre o elemento i de teste e o elemento j de treinamento
            distancia_teste_train.append(dist(dados_teste[i], dados_train[j], len(dados_teste[i])))

        # ordena a lista de dist√¢ncia e r√≥tulos juntos para que fiquem com os mesmos √≠ndices nos 
        # elementos correspondentes; ent√£o, seleciona a lista com os r√≥tulos j√° ordenados
        rotulos_ordenados = [y for x, y in sorted(zip(distancia_teste_train, rotulo_train))]

        # salva somente a coluna com os r√≥tulos, que √© o valor interessante para o problema
        rotulos_ordenados = [row[0] for row in rotulos_ordenados]

        # seleciona os k primeiros elementos dos r√≥tulos, calcula a quantidade de ocorr√™ncias 
        # para cada valor e pega o valor mais comum encontrado
        rotulos.append(ct(rotulos_ordenados[:k]).most_common(1)[0][0])
    
    return rotulos

# carrega grupo de dados
mat = scipy.loadmat('grupoDados3.mat')
grupo_test = mat['grupoTest']
grupo_train = mat['grupoTrain']
test_rots = mat['testRots']
train_rots = mat['trainRots']

# Q3.1: Aplique o kNN ao problema usando k = 1. Qual √© a acur√°cia na classifica√ß√£o?
# Aplicando o kNN com k igual a 1, obteve-se uma acur√°cia de 70%
rotulo_previsto_1 = meu_knn(grupo_train, train_rots, grupo_test, 1, False)
valor_acuracia_1 = acuracia(rotulo_previsto_1, test_rots)
print('Q3.1 - Acur√°cia obtida: ', valor_acuracia_1, end='%\n\n')
visualiza_pontos(grupo_test, rotulo_previsto_1, 0, 1)

# Q3.2: A acur√°cia pode ser igual a 92% com o kNN. Descubra por que o resultado atual √© muito menor.
#       Ajuste o conjunto de dados ou k de tal forma que a acur√°cia se torne 92% e explique o que voc√™ fez e
#       por qu√™.
# O resultado ficou bem menor, pois apenas um vizinho mais pr√≥ximo n√£o foi suficiente para fazer a classifica√ß√£o dos
# elementos de teste. Abaixo s√£o calculados novos valores para k, a fim de obter a maior acur√°cia poss√≠vel.
# Com k igual a 10, p√¥de-se alcan√ßar a acur√°cia de 92%. Isso foi feito para que cada elemento de teste seja classificado
# considerando um contexto maior da vizinhan√ßa e n√£o apenas o mais pr√≥ximo.

maior_acuracia = 0
melhor_k = 0
melhores_rotulos = []
for i in range(1, len(grupo_train)):
    rotulo_previsto = meu_knn(grupo_train, train_rots, grupo_test, i, False)
    valor_acuracia = acuracia(rotulo_previsto, test_rots)

    if valor_acuracia > maior_acuracia:
        maior_acuracia = valor_acuracia
        melhor_k = i
        melhores_rotulos = rotulo_previsto
print('Q3.2 - Acur√°cia obtida: ', maior_acuracia, end='%\n')
print('K:', melhor_k, end='\n')
visualiza_pontos(grupo_test, rotulo_previsto_1, 0, 1)